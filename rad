import os
import numpy as np
import torch
from torch.utils.data import Dataset, DataLoader
from torch.nn.parallel import DataParallel
from torch.optim import Adam
from tqdm import tqdm
import matplotlib.pyplot as plt
import csv
from custom_swin_unetr import CustomSwinUNETR 
from monai.losses import DiceFocalLoss, TverskyLoss
from monai.metrics import DiceMetric, MeanIoU, HausdorffDistanceMetric

# Main Function
def main():
    # GPU Setup
    os.environ["CUDA_VISIBLE_DEVICES"] = "5, 6"
    torch.cuda.set_device(0)

    if torch.cuda.is_available():
        for i in range(torch.cuda.device_count()):
            print(f"GPU {i}: {torch.cuda.get_device_name(i)}")

    
    # Dataset Definition
    class VLDataset(Dataset):
        def __init__(self, data_dir, transform=None):
            """
            Args:
                data_dir (str): Directory containing the dataset files (e.g., train, valid, test).
                transform (callable, optional): Optional transform to be applied on a sample.
            """
            self.data_dir = data_dir
            self.images_dir = os.path.join(data_dir, "images")
            self.masks_dir = os.path.join(data_dir, "masks")
            self.embeddings_dir = os.path.join(data_dir, "embeddings")
            self.patient_ids = [f.split('.')[0] for f in os.listdir(self.images_dir)]
            self.transform = transform

        def __len__(self):
            return len(self.patient_ids)

        def __getitem__(self, idx):
            patient_id = self.patient_ids[idx]
            
            # File paths
            image_path = os.path.join(self.images_dir, f"{patient_id}.npz")
            mask_path = os.path.join(self.masks_dir, f"{patient_id}.npz")
            embedding_path = os.path.join(self.embeddings_dir, f"{patient_id}.npz")
            
            # Load data
            ct_images = np.load(image_path)['ct_images']  # Replace 'ct_images' with actual key if different
            masks = np.load(mask_path)['masks']  # Replace 'masks' with actual key if different
            embeddings = np.load(embedding_path)['embeddings']  # Replace 'embeddings' with actual key if different
            
            # Convert to tensors
            ct_images = torch.tensor(ct_images, dtype=torch.float32).unsqueeze(0)  # Add channel dimension
            masks = torch.tensor(masks, dtype=torch.long)
            embeddings = torch.tensor(embeddings, dtype=torch.float32)
            
            # Create sample
            sample = {"image": ct_images, "label": masks, "embedding": embeddings}
            
            # Apply transformations if provided
            if self.transform:
                sample = self.transform(sample)
            
            return sample


    class Transform:
        def __init__(self, crop_size=(64, 336, 336)):
            self.crop_size = crop_size

        def __call__(self, sample):
            image, label, embedding = sample['image'], sample['label'], sample['embedding']
            # Clip the CT images to the range [-1000, 600]
            if image.min() < -2000:
                image = image.clip(-1000, 600)   
            else:
                image = image.clip(0, 1600)
            # Get the current shape of the image
            depth, height, width = image.shape[1:]
            crop_d, crop_h, crop_w = self.crop_size
            # Calculate cropping indices
            d1 = (depth - crop_d) // 2
            h1 = (height - crop_h) // 2
            w1 = (width - crop_w) // 2
            # Perform cropping on the image and label
            image = image[:, d1:d1+crop_d, h1:h1+crop_h, w1:w1+crop_w]
            label = label[d1:d1+crop_d, h1:h1+crop_h, w1:w1+crop_w]               
            # normalize the image
            image = (image - (-346.806)) / 661.800
            # Return the transformed sample
            return {
                "image": image,
                "label": label,
                "embedding": embedding
            }


    # Dataset and DataLoader Setup
    data_dir = "/scratch/mingma/HN/Radcure/Data/new"
    transform = Transform(crop_size=(64, 352, 352))
    train_dataset = VLDataset(os.path.join(data_dir, 'train'), transform=transform)
    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=48)
    val_dataset = VLDataset(os.path.join(data_dir, 'valid'), transform=transform)
    val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=48)
    test_dataset = VLDataset(os.path.join(data_dir, 'test'), transform=transform)
    test_loader = DataLoader(test_dataset, batch_size=2, shuffle=True, num_workers=48)

    # Model Initialization
    Radformer = CustomSwinUNETR(
        img_size=[64, 352, 352],
        in_channels=1,
        l_in_channels=768,
        out_channels=1,
        feature_size=48
    )
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    model = Radformer.to(device)
    model = DataParallel(model)

    pretrained_weights_path = '/scratch/mingma/HN/Radcure/Code/model/pretrained_weights/fold1_f48_ep300_4gpu_dice0_9059/model.pt'
    pretrained_weights = torch.load(pretrained_weights_path, map_location=device)
    state_dict = pretrained_weights['state_dict']  # 提取预训练模型的 state_dict
    swin_weights = {f'module.{k}': v for k, v in state_dict.items() if ('swinViT' in k) and ('patch_embed.proj.weight' not in k)}  # 筛选 Swin Transformer 层的权重
    model_dict = model.state_dict()  # 获取当前模型的 state_dict
    swin_weights = {k: v for k, v in swin_weights.items()}  # 确保键匹配
    model_dict.update(swin_weights)
    model.load_state_dict(model_dict)
    print(f"Loaded {len(swin_weights)} Swin Transformer layers from pre-trained weights.")

    # Training Setup
    learning_rate = 4e-4
    weight_decay = 1e-3
    num_epochs = 100
    optimizer = Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)

    # Losses
    dice_focal_loss = DiceFocalLoss(include_background=True, to_onehot_y=False, sigmoid=True, softmax=False)
    tversky_loss = TverskyLoss(include_background=True, to_onehot_y=False, sigmoid=True, alpha=0.5, beta=0.5)

    def composite_loss(y_pred, y_true):
        """
        Composite loss combining Dice Focal Loss and Tversky Loss.
        """
        l_dfc = dice_focal_loss(y_pred, y_true)
        l_tvr = tversky_loss(y_pred, y_true)
        return l_dfc + l_tvr
    
    # Metrics
    dice_metric = DiceMetric(include_background=True, reduction="mean", get_not_nans=True)
    iou_metric = MeanIoU(include_background=True, reduction="mean", get_not_nans=True)
    hd95_metric = HausdorffDistanceMetric(include_background=True, percentile=95, reduction="mean", get_not_nans=True)

    # CSV File Setup
    csv_path = '/scratch/mingma/HN/Radcure/Code/model/Radformer_try/v8/training_validation_metrics.csv'
    if not os.path.exists(csv_path):
        with open(csv_path, mode='w', newline='') as file:
            writer = csv.writer(file)
            writer.writerow([
                "Epoch", "Train Loss", "Valid Loss", 
                "Train Dice Score", "Train IoU Score", "Train HD95 Score", 
                "Valid Dice Score", "Valid IoU Score", "Valid HD95 Score", 
                "Test Dice Score", "Test IoU Score", "Test HD95 Score"
            ])
        print(f"Created new CSV file: {csv_path}")
    else:
        print(f"CSV file already exists, appending to: {csv_path}")
        
    # Training Loop
    def load_checkpoint(checkpoint_dir, model, optimizer, device):
        checkpoint_path = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')
        if not os.path.exists(checkpoint_path):
            print("No checkpoint found. Starting training from scratch.")
            return 0
        checkpoint = torch.load(checkpoint_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        epoch = checkpoint['epoch']
        loss = checkpoint['loss']
        print(f"Loaded checkpoint from {checkpoint_path}: epoch {epoch+1}, loss {loss:.6f}")
        return epoch + 1

    checkpoint_dir = '/scratch/mingma/HN/Radcure/Code/model/Radformer_try/v8/checkpoints'
    os.makedirs(checkpoint_dir, exist_ok=True)
    output_dir_train = "/scratch/mingma/HN/Radcure/Code/model/Radformer_try/v8/output_imgs/train"
    output_dir_test = "/scratch/mingma/HN/Radcure/Code/model/Radformer_try/v8/output_imgs/test"
    os.makedirs(output_dir_train, exist_ok=True)
    os.makedirs(output_dir_test, exist_ok=True)
    start_epoch = load_checkpoint(checkpoint_dir, model, optimizer, device)
    best_val_dice_score = 0.5

    for epoch in range(start_epoch, num_epochs):
        model.train()
        train_epoch_loss = 0
        train_dice_scores, train_iou_scores, train_hd95_scores = [], [], []
        
        for batch_data in tqdm(train_loader, desc=f"Training Epoch {epoch + 1}/{num_epochs}", miniters=1, ncols=80, leave=True):
            inputs, labels, embeddings = batch_data["image"].to(device), batch_data["label"].to(device), batch_data["embedding"].to(device)
            labels = labels.unsqueeze(1)
            embeddings = embeddings.permute(0, 2, 1)            
            optimizer.zero_grad()
            outputs = model(inputs, embeddings)            
            # Compute training loss
            loss = composite_loss(outputs, labels)
            loss.backward()
            optimizer.step()            
            train_epoch_loss += loss.item()
            # Compute metrics
            threshold = 0.5
            outputs_binary = (torch.sigmoid(outputs) > threshold).float() 
            # Dice Metric
            dice_metric(y_pred=outputs_binary, y=labels)
            train_dice_scores.append(dice_metric.aggregate()[0].item())            
            # IoU Metric
            iou_metric(y_pred=outputs_binary, y=labels)
            train_iou_scores.append(iou_metric.aggregate()[0].item())            
            # HD95 Metric
            hd95_metric(y_pred=outputs_binary, y=labels)
            train_hd95_scores.append(hd95_metric.aggregate()[0].item())

        # Reset metrics after aggregation
        dice_metric.reset()
        iou_metric.reset()
        hd95_metric.reset()

        # Save training images
        slice_indices = [24, 28, 32, 36, 40]
        fig, axes = plt.subplots(3, len(slice_indices), figsize=(20, 10))
        for i, slice_index in enumerate(slice_indices):
            slice_input = inputs[0, 0, slice_index - 1].detach().cpu()
            slice_output = outputs_binary[0, 0, slice_index - 1].detach().cpu()
            slice_labels = labels[0, 0, slice_index - 1].detach().cpu()                    
            axes[0, i].imshow(slice_input.numpy(), cmap='gray')
            axes[0, i].set_title(f"Input - Slice {slice_index}")
            axes[0, i].axis('off')                    
            axes[1, i].imshow(slice_output.numpy(), cmap='gray')
            axes[1, i].set_title(f"Outputs - Slice {slice_index}")
            axes[1, i].axis('off')                    
            axes[2, i].imshow(slice_labels.numpy(), cmap='gray')
            axes[2, i].set_title(f"Labels - Slice {slice_index}")
            axes[2, i].axis('off')                    
        img_path = os.path.join(output_dir_train, f"epoch_{epoch+1}.png")
        plt.tight_layout()
        plt.savefig(img_path)
        plt.close(fig)

        avg_train_loss = train_epoch_loss / len(train_loader)
        avg_train_dice_score = sum(train_dice_scores) / len(train_dice_scores)
        avg_train_iou_score = sum(train_iou_scores) / len(train_iou_scores)
        avg_train_hd95_score = sum(train_hd95_scores) / len(train_hd95_scores)

        print(f"Epoch {epoch + 1}/{num_epochs}, Training Loss: {avg_train_loss:.6f}, Dice Score: {avg_train_dice_score:.4f}, IoU Score: {avg_train_iou_score:.4f}, HD95 Score: {avg_train_hd95_score:.4f}")

        # Save checkpoints 
        checkpoint = {
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': train_epoch_loss / len(train_loader),
        }
        checkpoint_path = os.path.join(checkpoint_dir, 'latest_checkpoint.pth')
        torch.save(checkpoint, checkpoint_path)
        # print(f"Checkpoint saved: {checkpoint_path}")


        # Validation Phase
        model.eval()
        with torch.no_grad():
            val_epoch_loss = 0
            val_dice_scores, val_iou_scores, val_hd95_scores = [], [], []
            for val_data in tqdm(val_loader, desc=f"Validation Epoch {epoch + 1}/{num_epochs}", miniters=1, ncols=80):
                val_inputs, val_labels, val_embeddings = val_data["image"].to(device), val_data["label"].to(device), val_data["embedding"].to(device)
                val_labels = val_labels.unsqueeze(1)
                val_embeddings = val_embeddings.permute(0, 2, 1)
                val_outputs = model(val_inputs, val_embeddings)                
                # Compute validation loss
                val_loss = composite_loss(val_outputs, val_labels)
                val_epoch_loss += val_loss.item()
                # Compute metrics
                val_outputs_binary = (torch.sigmoid(val_outputs) > threshold).float() 
                # Dice Metric
                dice_metric(y_pred=val_outputs_binary, y=val_labels)
                val_dice_scores.append(dice_metric.aggregate()[0].item())                
                # IoU Metric
                iou_metric(y_pred=val_outputs_binary, y=val_labels)
                val_iou_scores.append(iou_metric.aggregate()[0].item())                
                # HD95 Metric
                hd95_metric(y_pred=val_outputs_binary, y=val_labels)
                val_hd95_scores.append(hd95_metric.aggregate()[0].item())
            
            # Reset metrics after aggregation
            dice_metric.reset()
            iou_metric.reset()
            hd95_metric.reset()            
            avg_val_loss = val_epoch_loss / len(val_loader)
            avg_val_dice_score = sum(val_dice_scores) / len(val_dice_scores)
            avg_val_iou_score = sum(val_iou_scores) / len(val_iou_scores)
            avg_val_hd95_score = sum(val_hd95_scores) / len(val_hd95_scores)
            print(f"Validation - Loss: {avg_val_loss:.6f}, Dice Score: {avg_val_dice_score:.4f}, IoU Score: {avg_val_iou_score:.4f}, HD95 Score: {avg_val_hd95_score:.4f}")

            # Save best model
            if avg_val_dice_score > best_val_dice_score:
                best_val_dice_score = avg_val_dice_score
                torch.save({
                    'epoch': epoch + 1,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'loss': avg_val_loss,
                }, os.path.join(checkpoint_dir, 'best_model.pth'))
                print(f"Best model saved at epoch {epoch+1} with validation Dice score: {best_val_dice_score:.4f}")


        # Test Phase
        with torch.no_grad():
            test_dice_scores, test_iou_scores, test_hd95_scores = [], [], []
            for test_data in tqdm(test_loader, desc=f"Test Epoch {epoch + 1}/{num_epochs}", miniters=1, ncols=80):
                test_inputs, test_labels, test_embeddings = test_data["image"].to(device), test_data["label"].to(device), test_data["embedding"].to(device)
                test_labels = test_labels.unsqueeze(1)
                test_embeddings = test_embeddings.permute(0, 2, 1)
                test_outputs = model(test_inputs, test_embeddings)
                # Compute metrics
                test_outputs_binary = (torch.sigmoid(test_outputs) > threshold).float()                 
                # Dice Metric
                dice_metric(y_pred=test_outputs_binary, y=test_labels)
                test_dice_scores.append(dice_metric.aggregate()[0].item())                
                # IoU Metric
                iou_metric(y_pred=test_outputs_binary, y=test_labels)
                test_iou_scores.append(iou_metric.aggregate()[0].item())                
                # HD95 Metric
                hd95_metric(y_pred=test_outputs_binary, y=test_labels)
                test_hd95_scores.append(hd95_metric.aggregate()[0].item())
            
            # Reset metrics after aggregation
            dice_metric.reset()
            iou_metric.reset()
            hd95_metric.reset()

            # Save test images
            slice_indices = [24, 28, 32, 36, 40]
            fig, axes = plt.subplots(3, len(slice_indices), figsize=(20, 10))
            for i, slice_index in enumerate(slice_indices):
                slice_input = test_inputs[0, 0, slice_index - 1].detach().cpu()
                slice_output = test_outputs_binary[0, 0, slice_index - 1].detach().cpu()
                slice_labels = test_labels[0, 0, slice_index - 1].detach().cpu()                    
                axes[0, i].imshow(slice_input.numpy(), cmap='gray')
                axes[0, i].set_title(f"Input - Slice {slice_index}")
                axes[0, i].axis('off')                    
                axes[1, i].imshow(slice_output.numpy(), cmap='gray')
                axes[1, i].set_title(f"Outputs - Slice {slice_index}")
                axes[1, i].axis('off')                    
                axes[2, i].imshow(slice_labels.numpy(), cmap='gray')
                axes[2, i].set_title(f"Labels - Slice {slice_index}")
                axes[2, i].axis('off')                    
            img_path = os.path.join(output_dir_test, f"epoch_{epoch+1}.png")
            plt.tight_layout()
            plt.savefig(img_path)
            plt.close(fig)

            avg_test_dice_score = sum(test_dice_scores) / len(test_dice_scores)
            avg_test_iou_score = sum(test_iou_scores) / len(test_iou_scores)
            avg_test_hd95_score = sum(test_hd95_scores) / len(test_hd95_scores)            
            print(f"Test - Dice Score: {avg_test_dice_score:.4f}, IoU Score: {avg_test_iou_score:.4f}, HD95 Score: {avg_test_hd95_score:.4f}")

            # Save metrics to CSV file
            with open(csv_path, mode='a', newline='') as file:
                writer = csv.writer(file)
                writer.writerow([epoch + 1, avg_train_loss, avg_val_loss, avg_train_dice_score, avg_train_iou_score, avg_train_hd95_score, avg_val_dice_score, avg_val_iou_score, avg_val_hd95_score, avg_test_dice_score, avg_test_iou_score, avg_test_hd95_score])

    # Save final checkpoint after training
    checkpoint = {
        'epoch': num_epochs,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': avg_train_loss,
    }
    torch.save(checkpoint, 'checkpoint_final.pth')


if __name__ == "__main__":
    main()
    input("按 Enter 键退出...")
